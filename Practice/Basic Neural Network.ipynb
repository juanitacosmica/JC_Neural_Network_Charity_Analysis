{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7064a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "import sklearn as skl\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1924bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=78)\n",
    "#import make_blobs: from sklearn.datasets import make_blobs\n",
    "#Replace this line: X, y = mglearn.datasets.make_forge() with this line:\n",
    "#X,y = make_blobs()\n",
    "\n",
    "# Creating a DataFrame with the dummy data\n",
    "df = pd.DataFrame(X, columns=[\"Feature 1\", \"Feature 2\"])\n",
    "df[\"Target\"] = y\n",
    "\n",
    "# Plotting the dummy data\n",
    "df.plot.scatter(x=\"Feature 1\", y=\"Feature 2\", c=\"Target\", colormap=\"winter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ac79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Sequential model\n",
    "nn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde58107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our first Dense layer, including the input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"relu\", input_dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28261e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a004f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a50bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification of a new set of blob data\n",
    "new_X, new_Y = make_blobs(n_samples=10, centers=2, n_features=2, random_state=78)\n",
    "new_X_scaled = X_scaler.transform(new_X)\n",
    "(nn_model.predict(new_X_scaled) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71374e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Creating dummy nonlinear data\n",
    "X_moons, y_moons = make_moons(n_samples=1000, noise=0.08, random_state=78)\n",
    "\n",
    "# Transforming y_moons to a vertical vector\n",
    "y_moons = y_moons.reshape(-1, 1)\n",
    "\n",
    "# Creating a DataFrame to plot the nonlinear dummy data\n",
    "df_moons = pd.DataFrame(X_moons, columns=[\"Feature 1\", \"Feature 2\"])\n",
    "df_moons[\"Target\"] = y_moons\n",
    "\n",
    "# Plot the nonlinear dummy data\n",
    "df_moons.plot.scatter(x=\"Feature 1\",y=\"Feature 2\", c=\"Target\",colormap=\"winter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4920263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing sets\n",
    "X_moon_train, X_moon_test, y_moon_train, y_moon_test = train_test_split(\n",
    "    X_moons, y_moons, random_state=78\n",
    ")\n",
    "\n",
    "# Create the scaler instance\n",
    "X_moon_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_moon_scaler.fit(X_moon_train)\n",
    "\n",
    "# Scale the data\n",
    "X_moon_train_scaled = X_moon_scaler.transform(X_moon_train)\n",
    "X_moon_test_scaled = X_moon_scaler.transform(X_moon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de700add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with the nonlinear data\n",
    "model_moon = nn_model.fit(X_moon_train_scaled, y_moon_train, epochs=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(model_moon.history, index=range(1,len(model_moon.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb96e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our new Sequential model\n",
    "new_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5589757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the input and hidden layer\n",
    "number_inputs = 2\n",
    "number_hidden_nodes = 6\n",
    "\n",
    "new_model.add(tf.keras.layers.Dense(units=number_hidden_nodes, activation=\"relu\", input_dim=number_inputs))\n",
    "\n",
    "# Add the output layer that uses a probability activation function\n",
    "new_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "new_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model to the training data\n",
    "new_fit_model = new_model.fit(X_moon_train_scaled, y_moon_train, epochs=100, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
